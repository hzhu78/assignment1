# -*- coding: utf-8 -*-
"""HW12_Zhu, Haocheng.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s2l0EMjxvIr4VcBNedlV0FFygI56MJeX
"""


import urllib.request
from bs4 import BeautifulSoup
import pandas as pd

url = "http://example.com"
ourUrl = urllib.request.urlopen(url)
page1 = BeautifulSoup(ourUrl, 'html.parser')


print(page1.select('body'))


page_links = page1.find_all('a')


url2 = "https://www.iana.org/domains/example"
ourUrl2 = urllib.request.urlopen(url2)
page2 = BeautifulSoup(ourUrl2, 'html.parser')


print(page2.select('body'))

print(len(page2.find_all('table')))

header = list(page2.table.find_all('th'))
i = 0
for i in range(len(header)):
  header[i] = header[i].text
  i += 1

rows = list(page2.table.find_all('td'))
i = 0
for i in range(len(rows)):
  rows[i] = rows[i].text
  i+= 1
newrows = [rows[i:i+4] for i in range(0, len(rows), 4)]



list1 = [header, newrows]


df = pd.DataFrame((list1[1][i] for i in range(len(list1[1]))), columns = list1[0])

print(list1)
print(df)
